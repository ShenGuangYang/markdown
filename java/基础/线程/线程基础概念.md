# Java 线程基础



## volatile

### 初步认识volatile

下面这段代码，演示了一个使用 volatile 以及没使用 volatile 这个关键字，对于变量更新的影响

```java
public class VolatileDemo {
    public /*volatile*/ static boolean is_stop = false;

    public static void main(String[] args) throws InterruptedException {
        Thread thread = new Thread(() -> {
            while (!is_stop) {
            }
        });
        thread.start();
        System.out.println("begin start thread");
        thread.sleep(1000);
        is_stop = true;
    }
}
```



### volatile 的作用

volatile 可以使得在多处理器环境下保证了共享变量的可见性，那么到底什么是可见性呢？

可见性：在单线程的环境下，如果向一个变量先写入一个值，然后在没有写干涉的情况下读取这个变量的值，那这个时候读取到的这个变量的值应该是之前写入的那个值。这本来是一个很正常的事情。但是在多线程环境下，读和写发生在不同的线程中的时候，可能会出现，读线程不能及时的读取到其它线程写入的最新值。

为了实现跨线程写入的内存可见性，必须使用到一些机制来实现。而 volatile 就是这样一种机制。

**volatile 关键字是如何保证可见性的？**

使用hsdis-amd64.dll 查看前面演示的这段代码的汇编指令。

在运行的代码中，设置jvm参数如下：

```
-server 
-Xcomp 
-XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly 
-XX:CompileCommand=compileonly,*TestDemo.*
```

在修改带有 volatile 修饰的成员变量时，会多一个lock指令。lock是一种控制指令，在多处理器环境下，lock 汇编指令可以基础总线锁或者缓存锁的机制来达到可见性的一个效果。



## JMM

### JMM 定义

JMM 全程是java memory model 。（java内存模型）

导致可见性问题的根本原因是缓存以及重排序。而JMM实际上就是提供了合理的禁用缓存以及禁止重排序的方法。所以它最核心的价值在于解决可见性和有序性。

JMM 属于语言级别的抽象内存模型，可以简单理解为对硬件模型的抽象，它定义了共享内存中多线程程序读写操作的行为规范：在虚拟机中把共享变量存储到内存以及从内存中取出共享变量的底层实现细节。

通过这些规则来规范对内存的读写操作从而保证指令的正确性，它解决了CPU多级缓存、处理器优化、指令重排序导致的内存访问问题，保证了并发场景下的可见性。

需要注意的是，JMM 并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序，也就是说在JMM中，也会存在缓存一致性问题和指令重排序问题。只是 JMM 把底层的问题抽象到 JMM 层面，在基于CPU层面提供的内存屏障指令，以及限制编译器的重排序来解决并发问题。

JMM 抽象模型分为主内存、工作内存；

+ 主内存是所有线程共享的，一般是实例对象、静态字段、数组对象等存储在堆内存中的变量。

+ 工作内存是每个线程独占的，线程对变量得所有操作都必须在工作内存中进行，不能直接读写主内存中的变量，线程之间的共享变量值的传递都是基于主内存来完成的。

Java 内存模型底层实现可以简单的认为：通过内存屏障（memory barrier）禁止重排序，即时编译器根据具体的底层体系架构，将这些内存屏障替换成具体的CPU指令。对于编译器而言，内存屏障将会导致缓存的刷新操作。比如，对于 volatile ，编辑器将在 volatile 字段的读写操作前后个插入一些内存屏障。



### JMM是如何解决可见性有序性问题的



简单来说， JMM 提供了一些禁用缓存以及禁止重排序的方法，来解决可见性和有序性问题。

例如：volatile、synchronized、final



### JMM是如何解决顺序一致性问题

#### 重排序问题

为了提高程序的执行性能，编译器和处理器都会对指令做重排序。所谓的重排序就是指执行的指令顺序。

编译器的重排序指的是程序编写的指令在编译之后，指令可能会产生重排序来优化程序的执行性能。

编译器的重排序，JMM 提供了禁止特定类型的编译器重排序。 

处理器重排序，JMM 会要求编译器生成指令时，会插入内存屏障来禁止处理器重排序。

#### JMM的内存屏障

为了保证内存可见性，Java 编译器在生成指令序列的适当位置会插入内存屏障来禁止特定类型的处理器的重排序



## HappenBefore

它的意思表示的是前一个操作的结果对于后续操作是可见的，所以它是一种表达多个线程之间对于内存的可见性。

所以我们可以认为在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在happens-before 关系。这两个操作可以使同一个线程，也可以是不同的线程。

### JMM 中有哪些方法建立 happen-before 规则

#### 程序顺序规则

1. 一个线程中的每个操作，happens-before 于该线程中任意后续操作；可以简单认为是as-if-serial。单个线程中的代码顺序不管怎么变，对于结果来说是不变的顺序规则表示





## synchronized

在多线程并发编程中 synchronized 一直是元老级角色，很多人都会称呼它为重量级锁。但是，随着 java1.6对synchronized 进行了各种优化之后，有些情况下它就并不是那么重， Java 1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁。这块在后续我们会慢慢展开。

#### synchronized 的基本认识

synchronized  有三种方式来枷锁，分别是

1. 修饰实例方式，作用于当前实例加锁，进入同步代码前要获得当前实例的锁。
2. 静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁。
3. 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码块前要获得给定对象的锁。

不同的修饰类型，代表锁的控制粒度。

#### synchronized 的应用

```java
public class Demo {
    private static int count = 0;
    public static void inc() {
        synchronized (Demo.class) {
            count ++;
        }
    }
    
    public static void main(String[] args) throws Exception {
        for (int i=0;i<100;i++) {
            new Thread(()->Demo.inc()).start();
        }
        Thread.sleep(3000);
        System.out.println("运行结果" + count);
    }
}
```

#### 思考锁是如何存储的 

可以思考一下，要实现多线程的互斥特性，那这把锁需要哪些因素？

1. 锁需要有一个东西来表示，比如获得锁是什么状态、无锁状态是什么状态
2. 这个状态需要对多个线程共享



那么我们来分析，synchronized锁是如何存储的呢？观察synchronized 的整个语法发现，synchronized (lock) 是基于lock这个对象的什么周期来控制锁粒度的，你是不是锁的存储和这个lock对象有关系呢？

于是我们以对象在jvm内存中是如何存储作为切入点，去看看对象里面有什么特性能够实现锁。

##### 对象在内存中的布局

在Hotspot 虚拟机中，对象在内存中的存储布局，可以分为三个区域：对象头（Header）、实例数据（Instance Data）、对象填充 （Padding）





## 线程中的各种锁

### 偏向锁

可以通过设置jvm参数 UseBiasedLocking 来设置开启或关闭。

#### 偏向锁的基本原理

在大部分情况下，锁不仅仅不存在多线程竞争，而是总是由同一个线程多次获得，为了让线程获得锁的代价更低就引入了偏向锁的概念。怎么理解偏向锁呢？

当一个线程访问加了同步锁的代码块时，会在对象头中存储当前线程的id，后续这个线程进入和退出这段加了同步锁的代码时，不需要再次加锁和释放锁。而是直接比较对象头里面是否存储了指向当前线程的偏向锁。如果相等表示偏向锁是偏向于当前线程的，就不要再尝试获得锁了。

#### 偏向锁的获取逻辑

1. 首先获取锁对象的markword，判断是否处于可偏向状态。（biased_lock=1、且ThreadId为空）
2. 如果是可偏向状态，则通过CAS操作，把当前线程的id写入到markword
   + 如果cas成功，那么markword就会变成这样。表示已经获得了锁对象的偏向锁，接着执行同步代码块
   + 如果cas失败，说明有其他线程已经获得了偏向锁，这种情况说明当前锁存在竞争，需要撤销已经获得偏向锁的线程，并且把它持有的锁升级为轻量级锁
3. 如果是已偏向状态，需要检查markword中的存储的ThreadId是否等于当前线程的ThreadId
   + 如果相等，不需要在此获得锁，可直接执行同步代码块
   + 如果不相等，说明当前锁偏向于其他线程，需要撤销偏向锁并升级到轻量级锁

#### 偏向锁的撤销逻辑

偏向锁的撤销并不是把对象恢复到无锁可偏向状态（因为偏向锁并不存在锁释放的概念），而是在获取偏向锁的过程中，发现cas失败也就是存在线程竞争时，直接把被偏向的锁对象升级到被加了轻量级锁的状态。

对原持有偏向锁的线程进行撤销时，原获得偏向锁的线程有两种情况：

1. 原获得偏向锁的线程如果已经退出了临界区，也就是同步代码块执行完了，那么这个时候会把对象头设置成无锁状态并且争抢锁的线程可以基于cas重新偏向当前线程
2. 如果原获得偏向锁的线程的同步代码块还没有执行完，处于临界区之内，这个时候会把原获得偏向锁的线程升级为轻量级锁后继续执行同步代码块



### 轻量级锁

#### 轻量级锁的加锁逻辑

锁升级为轻量级锁之后，对象的markword也会进行相应的变化。升级为轻量级锁的过程：

1. 线程在自己栈桢中创建锁记录 LockRecord
2. 将锁对象的对象头中markword复制到线程的刚刚创建的锁记录中
3. 将锁记录中的owner指针指向锁对象、
4. 将锁对象的对象头的markword替换为执行所记录的指针。



#### 自旋锁

轻量级锁在加锁过程中，用到了自旋锁。

所谓自选，就是指当有另外一个线程来竞争锁时，这个线程会在原地循环等待，而不是把该线程给阻塞，知道那个获得锁的线程释放锁之后，这个线程就可以马上获得锁的。注，锁在循环的时候，会消耗cpu。

所以，轻量级锁适用于那些同步代码块执行的很快的场景，这样线程原地等待很短的事件就能够获得锁了。

不过自旋锁必须要有一定的条件控制，否则如果一个线程执行同步代码块的事件很长，那么这个线程不断的循环反而会消耗cpu自愿。默认情况下自选的次数是10次

可以通过preBlockSpin来修改

在jdk 1.6 之后，引入了自适应自旋锁，以为这自旋锁的次数不是股东不变的，而是根据前一次在同一个锁上自选的事件一级锁的拥有者的状态来决定。

如果在同一个锁对象上，自选等待刚刚成功获得过锁，并且持有锁的线程在运行中，那么虚拟机就会认为这次自选也是很有可能再次成功，进而它将允许自选等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，拿在以后尝试获得这个锁时将可能省略掉自选过程，直接阻塞线程，避免浪费处理器资源。



#### 轻量级锁的解锁

轻量级锁的锁释放逻辑其实就是获得锁的逆向逻辑，通过cas操作把线程栈桢中的lockrecord替换回到锁对象的markword中，如果成功表示没有竞争，如果失败，表示当前存在竞争，那么轻量级锁就会膨胀成为重量级锁。



### 重量级锁

当轻量级锁膨胀成重量级锁之后，意味着线程只能被挂起阻塞来等待被唤醒了。

通过monitor对象来实现重量级锁。





















